{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x_train sample data[array([ 70.,  80.,  82., ..., 106., 109.,  82.], dtype=float32), array([151., 150., 147., ..., 193., 183., 184.], dtype=float32)]\ny_train sample data[array([254., 254., 254., ...,  42., 129., 180.], dtype=float32), array([156., 184., 198., ..., 172., 167., 161.], dtype=float32)]\nx_test sample data[0, 0]\ny_test sample data[array([254., 254., 254., ...,  42., 129., 180.], dtype=float32), array([156., 184., 198., ..., 172., 167., 161.], dtype=float32)]\n"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/paul/Documents/AI/Datasets/fer2013.csv')\n",
    "\n",
    "#print(data.info())\n",
    "#print(data['Usage'].value_counts())\n",
    "#print(data.head())\n",
    "\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    val = row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            x_train.append(np.array(val, 'float32'))\n",
    "            y_train.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            x_test.append(np.array(val, 'float32'))\n",
    "            y_test.append(row['emotion'])\n",
    "    except:\n",
    "        print(f'error occured at index:{index} and row:{row}')\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "width, height = 48, 48\n",
    "              \n",
    "print(f'x_train sample data{x_train[0:2]}')\n",
    "print(f'y_train sample data{x_test[0:2]}')\n",
    "print(f'x_test sample data{y_train[0:2]}')\n",
    "print(f'y_test sample data{x_test[0:2]}')\n",
    "\n",
    "x_train = np.array(x_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "y_train=to_categorical(y_train, num_classes=num_labels)\n",
    "y_test=to_categorical(y_test, num_classes=num_labels)\n",
    "\n",
    "#Normalizing Data\n",
    "x_train -= np.mean(x_train, axis=0)\n",
    "x_train /= np.mean(x_train, axis=0)\n",
    "\n",
    "x_test -= np.mean(x_test, axis=0)\n",
    "x_test /= np.mean(x_test, axis=0)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], width, height, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], width, height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n449/449 [==============================] - 246s 548ms/step - loss: 1.8476 - accuracy: 0.2434 - val_loss: 2.3794 - val_accuracy: 0.1792\nEpoch 2/50\n449/449 [==============================] - 249s 555ms/step - loss: 1.7894 - accuracy: 0.2554 - val_loss: 2.1601 - val_accuracy: 0.1953\nEpoch 3/50\n449/449 [==============================] - 249s 556ms/step - loss: 1.7572 - accuracy: 0.2765 - val_loss: 2.0374 - val_accuracy: 0.1688\nEpoch 4/50\n449/449 [==============================] - 249s 556ms/step - loss: 1.7230 - accuracy: 0.3061 - val_loss: 1.9694 - val_accuracy: 0.1775\nEpoch 5/50\n449/449 [==============================] - 250s 556ms/step - loss: 1.6910 - accuracy: 0.3259 - val_loss: 2.4838 - val_accuracy: 0.2048\nEpoch 6/50\n449/449 [==============================] - 250s 556ms/step - loss: 1.6651 - accuracy: 0.3375 - val_loss: 2.2558 - val_accuracy: 0.1864\nEpoch 7/50\n449/449 [==============================] - 249s 554ms/step - loss: 1.6400 - accuracy: 0.3534 - val_loss: 2.4045 - val_accuracy: 0.1884\nEpoch 8/50\n449/449 [==============================] - 243s 542ms/step - loss: 1.6176 - accuracy: 0.3634 - val_loss: 2.3725 - val_accuracy: 0.1984\nEpoch 9/50\n449/449 [==============================] - 242s 538ms/step - loss: 1.5995 - accuracy: 0.3718 - val_loss: 2.3169 - val_accuracy: 0.1839\nEpoch 10/50\n449/449 [==============================] - 241s 538ms/step - loss: 1.5731 - accuracy: 0.3785 - val_loss: 2.5696 - val_accuracy: 0.1822\nEpoch 11/50\n449/449 [==============================] - 242s 540ms/step - loss: 1.5489 - accuracy: 0.3927 - val_loss: 2.4043 - val_accuracy: 0.1900\nEpoch 12/50\n449/449 [==============================] - 242s 539ms/step - loss: 1.5283 - accuracy: 0.4013 - val_loss: 2.4853 - val_accuracy: 0.1858\nEpoch 13/50\n449/449 [==============================] - 242s 539ms/step - loss: 1.4955 - accuracy: 0.4181 - val_loss: 2.3589 - val_accuracy: 0.1850\nEpoch 14/50\n449/449 [==============================] - 241s 536ms/step - loss: 1.4574 - accuracy: 0.4333 - val_loss: 2.3670 - val_accuracy: 0.1758\nEpoch 15/50\n449/449 [==============================] - 241s 537ms/step - loss: 1.4262 - accuracy: 0.4412 - val_loss: 2.2840 - val_accuracy: 0.1886\nEpoch 16/50\n449/449 [==============================] - 243s 540ms/step - loss: 1.3824 - accuracy: 0.4648 - val_loss: 2.5898 - val_accuracy: 0.1828\nEpoch 17/50\n449/449 [==============================] - 241s 537ms/step - loss: 1.3350 - accuracy: 0.4863 - val_loss: 2.6640 - val_accuracy: 0.1872\nEpoch 18/50\n449/449 [==============================] - 242s 539ms/step - loss: 1.2887 - accuracy: 0.5070 - val_loss: 2.5476 - val_accuracy: 0.1833\nEpoch 19/50\n449/449 [==============================] - 242s 538ms/step - loss: 1.2329 - accuracy: 0.5291 - val_loss: 2.5501 - val_accuracy: 0.1962\nEpoch 20/50\n449/449 [==============================] - 242s 538ms/step - loss: 1.1666 - accuracy: 0.5556 - val_loss: 2.7374 - val_accuracy: 0.1753\nEpoch 21/50\n449/449 [==============================] - 241s 537ms/step - loss: 1.1040 - accuracy: 0.5830 - val_loss: 2.8414 - val_accuracy: 0.1964\nEpoch 22/50\n449/449 [==============================] - 241s 538ms/step - loss: 1.0453 - accuracy: 0.6045 - val_loss: 3.4713 - val_accuracy: 0.2062\nEpoch 23/50\n449/449 [==============================] - 241s 537ms/step - loss: 0.9964 - accuracy: 0.6266 - val_loss: 3.1465 - val_accuracy: 0.2168\nEpoch 24/50\n449/449 [==============================] - 240s 535ms/step - loss: 0.9300 - accuracy: 0.6534 - val_loss: 3.6712 - val_accuracy: 0.2171\nEpoch 25/50\n449/449 [==============================] - 241s 536ms/step - loss: 0.8824 - accuracy: 0.6690 - val_loss: 3.4530 - val_accuracy: 0.1911\nEpoch 26/50\n449/449 [==============================] - 241s 538ms/step - loss: 0.8292 - accuracy: 0.6948 - val_loss: 4.0059 - val_accuracy: 0.1981\nEpoch 27/50\n449/449 [==============================] - 241s 537ms/step - loss: 0.7834 - accuracy: 0.7086 - val_loss: 4.3488 - val_accuracy: 0.2062\nEpoch 28/50\n449/449 [==============================] - 240s 534ms/step - loss: 0.7302 - accuracy: 0.7311 - val_loss: 4.4152 - val_accuracy: 0.2120\nEpoch 29/50\n449/449 [==============================] - 241s 538ms/step - loss: 0.6970 - accuracy: 0.7445 - val_loss: 4.5572 - val_accuracy: 0.2229\nEpoch 30/50\n449/449 [==============================] - 241s 536ms/step - loss: 0.6706 - accuracy: 0.7545 - val_loss: 4.6259 - val_accuracy: 0.2221\nEpoch 31/50\n449/449 [==============================] - 241s 537ms/step - loss: 0.6342 - accuracy: 0.7683 - val_loss: 4.9707 - val_accuracy: 0.2123\nEpoch 32/50\n449/449 [==============================] - 243s 541ms/step - loss: 0.6061 - accuracy: 0.7794 - val_loss: 4.5007 - val_accuracy: 0.2118\nEpoch 33/50\n449/449 [==============================] - 242s 538ms/step - loss: 0.5682 - accuracy: 0.7925 - val_loss: 5.3715 - val_accuracy: 0.2045\nEpoch 34/50\n449/449 [==============================] - 243s 540ms/step - loss: 0.5483 - accuracy: 0.8024 - val_loss: 6.8997 - val_accuracy: 0.2196\nEpoch 35/50\n449/449 [==============================] - 242s 539ms/step - loss: 0.5258 - accuracy: 0.8085 - val_loss: 5.6206 - val_accuracy: 0.2037\nEpoch 36/50\n449/449 [==============================] - 242s 538ms/step - loss: 0.5110 - accuracy: 0.8146 - val_loss: 5.1461 - val_accuracy: 0.1984\nEpoch 37/50\n449/449 [==============================] - 242s 538ms/step - loss: 0.4958 - accuracy: 0.8220 - val_loss: 4.4007 - val_accuracy: 0.1914\nEpoch 38/50\n449/449 [==============================] - 242s 538ms/step - loss: 0.4740 - accuracy: 0.8303 - val_loss: 4.3741 - val_accuracy: 0.1914\nEpoch 39/50\n449/449 [==============================] - 243s 540ms/step - loss: 0.4644 - accuracy: 0.8320 - val_loss: 4.8467 - val_accuracy: 0.2045\nEpoch 40/50\n449/449 [==============================] - 241s 537ms/step - loss: 0.4462 - accuracy: 0.8378 - val_loss: 4.3863 - val_accuracy: 0.1998\nEpoch 41/50\n449/449 [==============================] - 242s 539ms/step - loss: 0.4399 - accuracy: 0.8418 - val_loss: 4.3094 - val_accuracy: 0.1867\nEpoch 42/50\n449/449 [==============================] - 241s 538ms/step - loss: 0.4273 - accuracy: 0.8473 - val_loss: 4.3917 - val_accuracy: 0.1987\nEpoch 43/50\n449/449 [==============================] - 241s 537ms/step - loss: 0.4074 - accuracy: 0.8541 - val_loss: 4.1128 - val_accuracy: 0.2073\nEpoch 44/50\n449/449 [==============================] - 241s 538ms/step - loss: 0.4032 - accuracy: 0.8560 - val_loss: 4.1524 - val_accuracy: 0.2003\nEpoch 45/50\n449/449 [==============================] - 242s 539ms/step - loss: 0.3795 - accuracy: 0.8638 - val_loss: 4.2246 - val_accuracy: 0.1747\nEpoch 46/50\n449/449 [==============================] - 243s 540ms/step - loss: 0.3890 - accuracy: 0.8623 - val_loss: 4.5296 - val_accuracy: 0.1839\nEpoch 47/50\n449/449 [==============================] - 242s 540ms/step - loss: 0.3721 - accuracy: 0.8659 - val_loss: 5.3805 - val_accuracy: 0.1911\nEpoch 48/50\n449/449 [==============================] - 243s 540ms/step - loss: 0.3554 - accuracy: 0.8738 - val_loss: 6.3773 - val_accuracy: 0.2059\nEpoch 49/50\n449/449 [==============================] - 243s 540ms/step - loss: 0.3539 - accuracy: 0.8760 - val_loss: 5.9438 - val_accuracy: 0.1975\nEpoch 50/50\n449/449 [==============================] - 243s 541ms/step - loss: 0.3433 - accuracy: 0.8803 - val_loss: 5.7451 - val_accuracy: 0.1987\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#first convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(x_train.shape[1:])))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#second convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#third convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1204, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1204, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "\n",
    "fer_json=model.to_json()\n",
    "with open('fer_model.json','w') as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights('fer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('femodel.json','w') as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights('feweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "emotion                                             pixels        Usage\n0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n...        ...                                                ...          ...\n35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n\n[35887 rows x 3 columns]\n"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/paul/Documents/AI/Datasets/fer2013.csv')\n",
    "\n",
    "#print(data.info())\n",
    "#print(data['Usage'].value_counts())\n",
    "#print(data.head())\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}